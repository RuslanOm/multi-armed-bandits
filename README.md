# Multi-armed bandits
Основными источниками алгоритмов и методов послужили следующие статьи:
* [A Contextual-Bandit Approach to Personalized News Article Recommendation](https://arxiv.org/pdf/1003.0146.pdf): hybrid-linUCB, disjoint-linUCB.
* [Finite-time Analysis of the Multiarmed Bandit Problemе](https://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf): e-greedy, UCB1.
* [An unbiased offline evaluation of contextual bandit algorithms with generalized linear models](http://proceedings.mlr.press/v26/li12a/li12a.pdf): offline evaluation

